{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Analysis\n",
    "\n",
    "You have learned some more about Python and the pandas module and tried it out on a\n",
    "fairly small dataset. You are now ready to explore a dataset from the Weather\n",
    "Underground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "\n",
    "Will be looking at investigating historic weather data.\n",
    "Of course, such data is hugely important for research into the large-scale, long-term shift\n",
    "in our planet’s weather patterns and average temperatures – climate change. However,\n",
    "such data is also incredibly useful for more mundane planning purposes. To demonstrate\n",
    "the learning this week, we will be using historic weather data to try and plan a\n",
    "summer holiday. You’ll use the data too and get a chance to work on your own\n",
    "project at the end of the week.\n",
    "The dataset we’ll use to do this will come from the [Weather Underground](http://www.wunderground.com/), which creates\n",
    "weather forecasts from data sent to them by a worldwide network of over 100,000 weather\n",
    "enthusiasts who have personal weather stations on their house or in their garden.\n",
    "In addition to creating weather forecasts from that data, the Weather Underground also\n",
    "keeps that data as historic weather records allowing members of the public to download\n",
    "weather datasets for a particular time period and location. These datasets are\n",
    "downloaded as CSV files, explained in the next step.\n",
    "Datasets are rarely ‘clean’ and fit for purpose, so it will be necessary to clean up the data\n",
    "and ‘mould it’ for your purposes. You will then learn how to visualise data by creating\n",
    "graphs using the `plot()` function\n",
    "\n",
    "We have downloaded the file London_2014.csv from our website, it can now be read into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london = pd.read_csv('London_2014.csv')\n",
    "london.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note that the right hand side of the table has been cropped to fit on the page.\n",
    "You’ll find out how to remove rogue spaces.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing initial spaces\n",
    "One of the problems often encountered with CSV files is rogue spaces before or after data\n",
    "values or column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned earlier, in What is a CSV file? , that each value or column name is separated\n",
    "by a comma. However, if you opened ‘London_2014.csv’ in a text editor, you would see\n",
    "that in the row of column names sometimes there are spaces after a comma:\n",
    "    \n",
    "`GMT,Max TemperatureC,Mean TemperatureC,Min TemperatureC,Dew PointC,\n",
    "MeanDew PointC,Min DewpointC,Max Humidity, Mean Humidity, Min Humidity,\n",
    "Max Sea Level PressurehPa, Mean Sea Level PressurehPa, Min Sea Level\n",
    "PressurehPa, Max VisibilityKm, Mean VisibilityKm, Min VisibilitykM, Max Wind\n",
    "SpeedKm/h, Mean Wind SpeedKm/h, Max Gust SpeedKm/h,Precipitationmm,\n",
    "CloudCover, Events,WindDirDegrees`\n",
    "\n",
    "For example, there is a space after the comma between Max Humidity and Mean\n",
    "Humidity. This means that when read_csv() reads the row of column names it will\n",
    "interpret a space after a comma as part of the next column name. So, for example, the\n",
    "column name after `'Max Humidity'` will be interpreted as `' Mean Humidity'` rather\n",
    "than what was intended, which is `'Mean Humidity'`. The ramification of this is that code\n",
    "such as:\n",
    "    \n",
    "`london[['Mean Humidity']]`\n",
    "\n",
    "will cause a key error (see Selecting a column ), as the column name is confusingly `'\n",
    "Mean Humidity '`.\n",
    "\n",
    "This can easily be rectified by adding another argument to the `read_csv()` function:\n",
    "`skipinitialspace=True`\n",
    "which will tell `read_csv()` to ignore any spaces after a comma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many columns for the dataframe to fit horizontally in this notebook, but they can be displayed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that <code>' Max Wind SpeedKm/h'</code> is prefixed by a space, as are other columm names such as <code>' Mean Humidity'</code> and <code>' Max Sea Level PressurehPa'</code>.\n",
    "\n",
    "The  <code>read_csv()</code> function has interpreted spaces after commas as being part of the next value. This can be rectified  easily by adding another argument to the <code>read_csv()</code> function to skip the initial spaces after a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "london = pd.read_csv('London_2014.csv', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extra characters\n",
    "\n",
    "Another problem shown above is that the final column is called <code>'WindDirDegrees&lt; br /&gt;'</code>.\n",
    "\n",
    "When the dataset was exported from the Weather Underground web site html line breaks were automatically added to each line in the file which <code>read_csv()</code> has interpreted as part of the column name and its values. This can be seen more clearly by looking at more values in the final column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the problem is worse than this, let’s look at some values in the final column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london['WindDirDegrees<br />'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s seems there is an html line break at the end of each line. If I opened `‘London_2014.\n",
    "csv’` in a text editor and looked at the ends of all lines in the file this would be confirmed.\n",
    "Once again I’m not going to edit the CSV file but rather fix the problem in the dataframe.\n",
    "\n",
    "To change `'WindDirDegrees\n",
    "'` to `'WindDirDegrees'` all I have to do is use the `rename()` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london = london.rename(columns={'WindDirDegrees<br />' : 'WindDirDegrees'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don’t worry about the syntax of the argument for `rename()` , just use this example as a\n",
    "template for whenever you need to change the name of a column.\n",
    "\n",
    "Now I need to get rid of those pesky html line breaks from the ends of the values in the `'WindDirDegrees'` column, so that\n",
    "they become something sensible. I can do that using the `string method rstrip()` which\n",
    "is used to remove characters from the `end or ‘rear’` of a string, just like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london['WindDirDegrees'] = london['WindDirDegrees'].str.rstrip('<br />')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again don’t worry too much about the syntax of the code and simply use it as a template\n",
    "for whenever you need to process a whole column of values stripping characters from the\n",
    "end of each string value.\n",
    "Let’s display the first few rows of the `' WindDirDegrees'`to confirm the changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london['WindDirDegrees'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Missing (also called null or not available) values are marked as NaN (not a number) in dataframes, these are one of the reasons to clean data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isnull()` method returns `True` for each row in a column that has a null value. The method can be used to select and display those rows. Scroll the table below to the right to check that the events column is only showing missing values.\n",
    "\n",
    "Finding missing values in a particular column can be done with the column method\n",
    "isnull() , like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london[london['Events'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code returns a series of Boolean values, where `True` indicates that the\n",
    "corresponding row in the `'Events'` column is missing a value and `False` indicates the\n",
    "presence of a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to deal with missing values is to replace them by some value. The column method `fillna()` fills all not available value cells with the value given as argument. In the example below, each missing event is replaced by the empty string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, as you did with the comparison expressions, you put this code within square brackets\n",
    "after the dataframe’s name, it will return a new dataframe consisting of all the rows without\n",
    "recorded events **(rain, fog, thunderstorm, etc.):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london[london['Events'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a new dataframe with 114 rows, showing that more than one in three days had no particular event recorded.\n",
    "If you scroll the table to the right, you will see that all values in the `'Events'` column are\n",
    "marked `NaN` , which stands for `‘Not a Number’`, but is also used to mark non-numeric\n",
    "missing values, like in this case (events are strings, not numbers).\n",
    "\n",
    "Once you know how much and where data is missing, you have to decide what to do:\n",
    "    \n",
    "- ignore those rows? \n",
    "- Replace with a fixed value? \n",
    "- Replace with a computed value, like the mean?\n",
    "\n",
    "In this case, only the first two options are possible. The method call `london.dropna()`\n",
    "will drop (remove) all rows that have a missing (non-available) value somewhere,\n",
    "returning a new dataframe. This will therefore also remove rows that have missing values\n",
    "in other columns.\n",
    "The column method `fillna()` will replace all non-available values with the value given\n",
    "as argument. For this case, each NaN could be replaced by the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "london['Events'] = london['Events'].fillna('')\n",
    "london[london['Events'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second line above will now show an empty dataframe, because there are no longer\n",
    "missing values in the events column.\n",
    "As a final note on missing values, pandas ignores them when computing numeric\n",
    "statistics, i.e. you don’t have to remove missing values before applying `sum(),\n",
    "median()` and other similar methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empty dataframe (no rows) confirms there are no more missing event values.\n",
    "\n",
    "Another way to deal with missing values is to ignore rows with them. The `dropna()` dataframe method returns a new dataframe where all rows with at least one non-available value have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "london.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the table above has fewer than 251 of the original 365 rows, so there must be further null values besides the 114 missing events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the value type of a column\n",
    "\n",
    "The function `read_csv()` may, for many reasons, wrongly interpret the data type of the\n",
    "values in a column, so when cleaning data it’s important to check the data types of each\n",
    "column are what is expected, and if necessary change them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of every column in a dataframe can be determined by looking at the dataframe's `dtypes` attribute, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "london.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above output, you can see the column names to the left and to the right the data\n",
    "types of the values in those columns.\n",
    "- **int64** is the pandas data type for whole numbers such as `55 or 2356`\n",
    "- **float64** is the pandas data type for decimal numbers such as `55.25 or 2356.00`\n",
    "- **object** is the pandas data type for strings such as 'hello world' or 'rain'\n",
    "Most of the column data types seem fine, however two are of concern, `'GMT'` and\n",
    "`'WindDirDegrees'` , both of which are of `type object`. Let’s take a look at\n",
    "`'WindDirDegrees'` first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing the data type of the `'WindDirDegrees'` column**\n",
    "\n",
    "The `read_csv()` method has interpreted the values in the `'WindDirDegrees'` column\n",
    "as strings `(type object )`. This is because in the CSV file the values in that column had all\n",
    "been suffixed with that html line break string\n",
    "so `read_csv()` had no alternative but to interpret the values as strings.\n",
    "The values in the `'WindDirDegrees'` column are meant to represent wind direction in\n",
    "terms of `degrees from true north (360) and meteorologists always define the wind\n",
    "direction as the direction the wind is coming from`. So if you stand so that the wind is\n",
    "blowing directly into your face, the direction you are facing names the wind, so a westerly\n",
    "wind is reported as 270 degrees. The compass rose shown below should make this\n",
    "clearer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be able to make queries such as ‘Get and display the rows where the wind\n",
    "direction is greater than 350 degrees’. To do this we need to change the data type of the\n",
    "`‘WindDirDegrees’` column from object to `type int64`. \n",
    "The type of all the values in a column can be changed using the <code>astype()</code> method. The following code will change the values in the <code>'WindDirDegrees'</code> column from strings (`object`) to integers (<code>int64</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london['WindDirDegrees'] = london['WindDirDegrees'].astype('int64')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the values in the `'WindDirDegrees'` column are of `type int64` and we can\n",
    "make our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london[london['WindDirDegrees'] > 350]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing the data type of the ‘GMT’ column**\n",
    "\n",
    "Recall that I noted that the `'GMT'` column was of type object , the type pandas uses for\n",
    "strings.\n",
    "\n",
    "The `'GMT'` column is supposed to represent dates. It would be helpful for the date values\n",
    "not to be strings to make it possible to make queries of the data such as `‘Return the row\n",
    "where the date is 4 June 2014’`.\n",
    "\n",
    "Pandas has a function called `to_datetime()` which can convert a column of `object\n",
    "(string)` values such as those in the `'GMT'` column into values of a proper date type called\n",
    "`datetime64`, just like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london['GMT'] = pd.to_datetime(london['GMT'])\n",
    "london.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can confirm that the `'WindDirDegrees'` column type has\n",
    "been changed from `object to int64` and that the `'GMT'` column type has been changed\n",
    "from `object to datetime64`.\n",
    "\n",
    "To make queries such as `‘Return the row where the date is 4 June 2014’` you’ll need to be\n",
    "able to create a `datetime64 value to represent June 4 2014`. It cannot be:\n",
    "`london[london['GMT'] == '2014-1-3']`\n",
    "because `‘2014-1-3’` is a string and the values in the `‘GMT’` column are of type\n",
    "`datetime64`. Instead you must create a `datetime64 value using thedatetime()`\n",
    "function like this:\n",
    "    \n",
    "`datetime(2014, 6, 4)`\n",
    "\n",
    "In the function call above, the first integer argument is the year, the second the month and\n",
    "the third the day.\n",
    "\n",
    "Let’s try the function out by executing the code to `‘Return the row where the date is 4\n",
    "June 2014’`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london[london['GMT'] == datetime(2014, 6, 4)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also now make more complex queries involving dates such as 'Return all the rows where the date is between 8 December and 12 December' can be made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = london['GMT']\n",
    "start = datetime(2014, 12, 8)\n",
    "end = datetime(2014, 12, 12)\n",
    "london[(dates >= start) & (dates <= end)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Now that the wind direction is given by a number, write code to select all days that had a northerly wind. Hint: select the rows where the direction is greater than or equal to 350 **or** smaller than or equal to 10, as the compass rose shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, write code to get and display all the rows in the dataframe that are beween 1 April 2014 and \n",
    "11 April 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, write two lines of code to display the first five rows that have a missing value in the `'Max Gust SpeedKm/h'` column. Hint: first select the missing value rows and store them in a new dataframe, then display the first five rows of the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
